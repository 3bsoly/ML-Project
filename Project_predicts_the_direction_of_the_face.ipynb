{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JX7pan_62Jxv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "import scipy.io as sio\n",
        "from math import cos, sin\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import mediapipe\n",
        "import warnings"
      ],
      "metadata": {
        "id": "Tx-gneXs8sK2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "6LV96NEC8y-C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile('/content/AFLW2000-3D.zip') == False:\n",
        "    !gdown --id 1fP3zvSCYjll_o_m7S12nvQLZ9MnsEoap\n",
        "    !unzip /content/AFLW2000-3D.zip"
      ],
      "metadata": {
        "id": "D01jqJk4zGS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract X_points, Y_points, labels from images\n",
        "x_points= []\n",
        "y_points = []\n",
        "labels = []\n",
        "file_names = sorted([Path(f).stem for f in glob.glob(\"AFLW2000/*.mat\")])\n",
        "faceModule = mediapipe.solutions.face_mesh\n",
        "for filename in file_names:\n",
        "  with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
        "    image = cv2.imread('AFLW2000/'+filename+'.jpg')\n",
        "    results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    if results.multi_face_landmarks != None:\n",
        "          face = results.multi_face_landmarks[0]\n",
        "          X = []\n",
        "          Y = []\n",
        "          for landmark in face.landmark:\n",
        "              X.append(landmark.x)\n",
        "              Y.append(landmark.y)\n",
        "          x_points.append(np.array(X))\n",
        "          y_points.append(np.array(Y))\n",
        "          mat_file = sio.loadmat('AFLW2000/'+filename+'.mat')\n",
        "          pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
        "          labels.append(pose_para)\n",
        "x_points = np.array(x_points)\n",
        "y_points = np.array(y_points)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "AcnS2FFtlVJ0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing data\n",
        "x_center_point = x_points - x_points[:,5].reshape(-1,1)\n",
        "y_center_point = y_points - y_points[:,5].reshape(-1,1)\n",
        "\n",
        "final_x = x_center_point / np.max(np.abs(x_center_point),axis=1).reshape(-1,1)\n",
        "final_y = y_center_point / np.max(np.abs(y_center_point),axis=1).reshape(-1,1)\n",
        "\n",
        "# Features\n",
        "feature = np.hstack([final_x,final_y])"
      ],
      "metadata": {
        "id": "w8LzNIycXlLW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_validation, labels_train, labels_validation = train_test_split(feature ,labels ,test_size=.2,random_state=40)"
      ],
      "metadata": {
        "id": "qLVtdbX1p9N8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the SVR model for data\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "model_svr = MultiOutputRegressor(SVR(kernel='rbf',C=3,gamma=0.01,degree=3,epsilon=0.005))\n",
        "model_svr.fit(features_train, labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "1GMIYoPB5eVK",
        "outputId": "42b866b0-1ff1-4148-f477-6792a23af730"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=SVR(C=3, epsilon=0.005, gamma=0.01))"
            ],
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=SVR(C=3, epsilon=0.005, gamma=0.01))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=SVR(C=3, epsilon=0.005, gamma=0.01))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=3, epsilon=0.005, gamma=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=3, epsilon=0.005, gamma=0.01)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train acc: \", model_svr.score(features_train,labels_train ))\n",
        "print(\"Validation Error: \",model_svr.score(features_validation,labels_validation ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNWiAqMT8IVp",
        "outputId": "c2800dc6-434e-40e3-cf4e-5eb1db74991f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc:  0.44659287276185106\n",
            "Validation Error:  0.8567949882037263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LF6oYY4MvusL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_axis(img, pitch, yaw, roll, tdx=None, tdy=None, size=100):\n",
        "    yaw = -yaw\n",
        "    if tdx != None and tdy != None:\n",
        "        tdx = tdx\n",
        "        tdy = tdy\n",
        "    else:\n",
        "        height, width = img.shape[:2]\n",
        "        tdx = width / 2\n",
        "        tdy = height / 2\n",
        "\n",
        "    # X-Axis pointing to right. drawn in red\n",
        "    x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
        "    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
        "\n",
        "    # Y-Axis | drawn in green\n",
        "    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
        "    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
        "\n",
        "    # Z-Axis (out of the screen) drawn in blue\n",
        "    x3 = size * (sin(yaw)) + tdx\n",
        "    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
        "\n",
        "    cv2.line(img, (int(tdx), int(tdy)), (int(x1), int(y1)), (0, 0, 255), 3)\n",
        "    cv2.line(img, (int(tdx), int(tdy)), (int(x2), int(y2)), (0, 255, 0), 3)\n",
        "    cv2.line(img, (int(tdx), int(tdy)), (int(x3), int(y3)), (255, 0, 0), 2)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "ESG2Bx_488un"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def landmarks(image):\n",
        "    x_features = []\n",
        "    y_features = []\n",
        "    with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
        "        results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_face_landmarks != None:\n",
        "            for face in results.multi_face_landmarks:\n",
        "                for landmark in face.landmark:\n",
        "                    x = landmark.x\n",
        "                    y = landmark.y\n",
        "                    shape = image.shape\n",
        "                    x_features.append(x*shape[1])\n",
        "                    y_features.append(y*shape[0])\n",
        "    if x_features:\n",
        "        x_features=np.array(x_features)\n",
        "        y_features=np.array(y_features)\n",
        "        img_features2=np.hstack([x_features,y_features])\n",
        "        x_center=x_features-x_features[5]\n",
        "        y_center=y_features-y_features[5]\n",
        "        final_x = x_center / np.max(np.abs(x_center))\n",
        "        final_y = y_center / np.max(np.abs(y_center))\n",
        "        features = np.hstack([final_x,final_y])\n",
        "    else:\n",
        "        features=[]\n",
        "        img_features2=[]\n",
        "    return features , x_features,y_features"
      ],
      "metadata": {
        "id": "IwBvYCW61m8d"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_pose(image, model):\n",
        "    img_features,x_features,y_features = landmarks(image)\n",
        "    if image.shape == (0,) or len(img_features) == 0:\n",
        "        return None,None,None\n",
        "    img_features = img_features.reshape(1,-1)\n",
        "    return model.predict(img_features), x_features , y_features"
      ],
      "metadata": {
        "id": "c74n4oe793xD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/WhatsApp Video 2024-03-03 at 9.05.53 PM.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "out = cv2.VideoWriter('new_axis_video.mp4',cv2.VideoWriter_fourcc('X','V','I','D'), 30, (frame_width,frame_height))\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    pose , x_features,y_features  = predict_pose(frame, model_svr) or (None,None)\n",
        "    if pose is not None:\n",
        "        pitch, yaw, roll = pose[0]\n",
        "        draw_axis(frame, pitch, yaw,roll,tdx=x_features[5],tdy=y_features[5] ,size = 100)\n",
        "    out.write(frame)\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "TSLv3JvP_c_c"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7H_TP4U9tk77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}